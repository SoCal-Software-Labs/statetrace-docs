"use strict";(self.webpackChunkstatetrace_docs=self.webpackChunkstatetrace_docs||[]).push([[477],{10:function(e){e.exports=JSON.parse('{"blogPosts":[{"id":"redis-server","metadata":{"permalink":"/blog/redis-server","source":"@site/blog/2021-11-09-elixir-redis-server/index.md","title":"Build an Elixir Redis Server that\'s 100x faster than HTTP","description":"Build a redis server in Elixir","date":"2021-11-09T00:00:00.000Z","formattedDate":"November 9, 2021","tags":[{"label":"redis","permalink":"/blog/tags/redis"},{"label":"elixir","permalink":"/blog/tags/elixir"},{"label":"api","permalink":"/blog/tags/api"},{"label":"http","permalink":"/blog/tags/http"}],"readingTime":6.16,"truncated":true,"authors":[{"name":"Kyle Hanson","title":"CEO of Statetrace","url":"https://github.com/hansonkd","imageURL":"https://github.com/hansonkd.png","key":"kyle-hanson"}],"nextItem":{"title":"Time for a Change - Announcing Statetrace","permalink":"/blog/time-for-a-change"}},"content":"Need a fast server and client? HTTP too slow? Try the Redis Protocol for lightning fast, low-overhead API calls. It\'s easy to implement and nearly every language has mature Redis clients that can connect.\\n\\n\x3c!--truncate--\x3e\\n\\n\x3c!-- ![Docusaurus Plushie](./ipanema.jpg) --\x3e\\n\\n<div style={{\\"background\\": \\"url(/img/ipanema.jpg)\\", \\"backgroundSize\\": \\"150px\\", width: \\"100%\\", height: \\"200px\\", \\"marginTop\\": \\"30px\\", \\"marginBottom\\": \\"30px\\"}}>\\n\\n</div>\\n\\n*This project was inspired by <a href=\\"https://github.com/hansonkd/Tino/\\">Tino</a>, the Redis/MsgPack framework for Python.*\\n\\nBuilding a server based on Redis Protocol from scratch can sound intimidating. But if you know what you are doing it can be relatively straight forward to implement. A huge shortcut involves using [Redix](https://github.com/whatyouhide/redix) to parse the binary stream in a fast and efficient manner.\\n\\nIn this article we will implement a Redis echo server and explain how to extend the server to handle your own custom commands. In the end, it results in a performance boost of over **100x** using Redis instead of HTTP.\\n\\nThis blog post assumes you are familar with Elixir and its Application structure. If you want to learn more about TCP connections and supervision, read the [official Elixir article](https://elixir-lang.org/getting-started/mix-otp/task-and-gen-tcp.html).\\n\\n## Advantages\\n\\nFirst before we get started, lets discuss some of the advantages. Building a server based on RESP (the Redis protocol) means you are cutting out a lot of overhead associated with HTTP. In addtion to a more lean protocol, nearly every language has a high-performance client built for Redis that allows pipelining. Pipelining combines commands as you send them for even greater efficiency. Most redis clients even support pooling for working at high concurrencies.\\n\\nWith these built in features, you don\'t have to do very much to talk to your server in an extremely high performance fashion. \\n\\n\\n## Reading the TCP connection\\n\\nTo get started building our server, we will need to accept a TCP connection. We do this by looping over `:gen_tcp.accept` and spawning a task.\\n\\n```elixir\\ndefmodule MyRedisServer.Redis do\\n  require Logger\\n  def accept(port) do\\n    {:ok, socket} = :gen_tcp.listen(port, [:binary, active: false, reuseaddr: true])\\n    Logger.info(\\"Accepting connections on port #{port}\\")\\n    loop_acceptor(socket)\\n  end\\n\\n  defp loop_acceptor(socket) do\\n    {:ok, client} = :gen_tcp.accept(socket)\\n\\n    {:ok, pid} =\\n      Task.start(fn ->\\n        serve(client, %{continuation: nil})\\n      end)\\n\\n    :ok = :gen_tcp.controlling_process(client, pid)\\n\\n    loop_acceptor(socket)\\n  end\\nend\\n```\\n\\nNow we are ready to read packets from the connection. Elixir\'s Redis client Redix includes an parser for us to use.\\n\\n```elixir\\ndefmodule MyRedisServer.Redis do\\n  ...\\n\\n  defp serve(socket, %{continuation: nil}) do\\n    case :gen_tcp.recv(socket, 0) do\\n      {:ok, data} ->  handle_parse(socket, Redix.Protocol.parse(data))\\n      {:error, :closed} -> :ok\\n    end\\n  end\\n\\n  defp serve(socket, %{continuation: fun}) do\\n    case :gen_tcp.recv(socket, 0) do\\n      {:ok, data} ->  handle_parse(socket, fun.(data))\\n      {:error, :closed} -> :ok\\n    end\\n  end\\nemd\\n```\\n\\nHandling the parse result is straight forward. Either an entire message was processed and we can handle it, and respond, or a partial message was recieved and we need to wait for more data.\\n\\n\\n```elixir\\ndefmodule MyRedisServer.Redis do\\n  ...\\n\\n  defp handle_parse(socket, {:continuation, fun}) do\\n    serve(socket, %{continuation: fun})\\n  end\\n\\n  defp handle_parse(socket, {:ok, req, left_over}) do\\n    resp = handle(req)\\n\\n    :gen_tcp.send(socket, Redix.Protocol.pack(resp))\\n\\n    case left_over do\\n      \\"\\" -> serve(socket, %{continuation: nil})\\n      _ -> handle_parse(socket, Redix.Protocol.parse(left_over))\\n    end\\n  end\\n\\n  def handle(data) do\\n    data\\n  end\\nend\\n```\\n\\n## Complete example\\n\\nFinally we are ready to put it all together. All the pieces come together to form a nice little echo server.\\n\\n```elixir\\ndefmodule MyRedisServer.Redis do\\n  require Logger\\n\\n  def accept(port) do\\n    {:ok, socket} = :gen_tcp.listen(port, [:binary, active: false, reuseaddr: true])\\n    Logger.info(\\"Accepting connections on port #{port}\\")\\n    loop_acceptor(socket)\\n  end\\n\\n  defp loop_acceptor(socket) do\\n    {:ok, client} = :gen_tcp.accept(socket)\\n\\n    {:ok, pid} =\\n      Task.start(fn ->\\n        serve(client, %{continuation: nil})\\n      end)\\n\\n    :ok = :gen_tcp.controlling_process(client, pid)\\n\\n    loop_acceptor(socket)\\n  end\\n\\n  defp serve(socket, %{continuation: nil}) do\\n    case :gen_tcp.recv(socket, 0) do\\n      {:ok, data} ->  handle_parse(socket, Redix.Protocol.parse(data))\\n      {:error, :closed} -> :ok\\n    end\\n  end\\n\\n  defp serve(socket, %{continuation: fun}) do\\n    case :gen_tcp.recv(socket, 0) do\\n      {:ok, data} ->  handle_parse(socket, fun.(data))\\n      {:error, :closed} -> :ok\\n    end\\n  end\\n\\n  defp handle_parse(socket, {:continuation, fun}) do\\n    serve(socket, %{continuation: fun})\\n  end\\n\\n  defp handle_parse(socket, {:ok, req, left_over}) do\\n    resp = handle(req)\\n\\n    :gen_tcp.send(socket, Redix.Protocol.pack(resp))\\n\\n    case left_over do\\n      \\"\\" -> serve(socket, %{continuation: nil})\\n      _ -> handle_parse(socket, Redix.Protocol.parse(left_over))\\n    end\\n  end\\n\\n  def handle(data) do\\n    data\\n  end\\nend\\n\\n```\\n\\n\\nRun this server in your Application\'s supervision tree:\\n\\n\\n```elixir\\n defmodule MyRedisServer.Application do\\n  use Application\\n\\n  ...\\n\\n  def start(_type, _args) do\\n    claims = get_license_claims!()\\n\\n    children = [\\n      ...,\\n      Supervisor.child_spec({Task, fn -> MyRedisServer.Redis.accept(3211) end},   restart: :permanent)\\n    ]\\n\\n    ...\\n\\n    Supervisor.start_link(children, opts)\\n  end\\nend\\n```\\n\\n## Connecting from a client\\n\\nStart your mix project and you should be able to connect to redis on 3211 and the command should echo what you send it.\\n\\n```elixir\\n> {:ok, conn} = Redix.start_link(\\"redis://localhost:3211\\")\\n> Redix.command(conn, [\\"COOL_COMMAND\\", \\"123\\"])\\n{:ok, [\\"COOL_COMMAND\\", \\"123\\"]}\\n```\\n\\nAdding commands to your new redis server is easy with pattern matching:\\n\\n```elixir\\ndefmodule MyRedisServer.Redis do\\n  ...\\n\\n  def handle([\\"PUT\\", key, val]) do\\n    Cachex.put(:my_cachex, key, val)\\n    [\\"OK\\"]\\n  end\\n\\n  def handle([\\"GET\\", key]) do\\n    [Cachex.get(:my_cachex, key)]\\n  end\\n\\n  def handle([\\"ECHO\\", msg]) do\\n    msg\\n  end\\n\\n  def handle(_data) do\\n    %Redix.Error{message: \\"UNKNOWN_COMMAND\\"}\\n  end\\nend\\n```\\n\\n## MsgPack\\n\\nMsgPack is essentially a faster, more compact version of JSON. Use it to serialize complex structures into binary data to pass back and forth between your API.\\n\\n\\n```elixir\\ndefmodule MyRedisServer.Redis do\\n  ...\\n\\n  def handle([command, payload]) do\\n    case handle_command(command, MsgPax.unpack!(payload)) do\\n        {:error, e} -> %Redix.Error{message: \\"ERROR #{e}\\"}\\n        value -> [MspPax.pack!(value)]\\n    end\\n  end\\n\\n  def hande(_) do\\n    %Redix.Error{message: \\"INMVALID_FORMAT\\"}\\n  end\\n\\n  defp handle_command(\\"PUT\\", [key, val]) do\\n    Cachex.put(:my_cachex, key, val)\\n    [\\"OK\\"]\\n  end\\n\\n  defp handle_command(\\"GET\\", key) do\\n    Cachex.get(:my_cachex, key)\\n  end\\n\\n  defp handle_command(\\"ECHO\\", msg) do\\n    msg\\n  end\\n\\n  defp handle_command(_command, _data) do\\n    {:error, \\"INVALID_COMMAND\\"}\\n  end\\nend\\n```\\n\\n## Benchmark\\n\\nFor this benchmark we will compare HTTP Phoenix to our Redis Server.\\n\\nOur HTTP Phoenix Controllers:\\n\\n```elixir\\n  # GET -> Text\\n  def bench(conn, %{\\"payload\\" => payload, \\"times\\" => times}) when is_binary(times) do\\n    text(conn, String.duplicate(payload, String.to_integer(times)))\\n  end\\n\\n  # POST -> JSON\\n  def bench(conn, %{\\"payload\\" => payload, \\"times\\" => times}) do\\n    json(conn, %{\\"data\\" => String.duplicate(payload, times)})\\n  end\\n```\\n\\nand our Redis server:\\n\\n```elixir\\n  def handle([\\"BENCH\\", payload, number]) do\\n    [String.duplicate(payload, String.to_integer(number))]\\n  end\\n```\\n\\nWe will use [Finch](https://github.com/sneako/finch) for the HTTP client, which labels itself as \\"performance focused\\".\\n\\nFor the full benchmark see [the source](https://gist.github.com/hansonkd/cd34329fe4f346e680b39a17d9988af4).\\n\\nWe will remotely call our functions using the Finch HTTP pool, a single Redix connection, or a pool of Redix connections. We will also test pipelining vs calling each command individually for Redix. We will call our remote function 1000 times concurrently and ask it to duplicate the string `\\"12345&?\\\\\\"678,\\\\n90\\"`  100 times and respond.\\n\\n\\n```bash\\nName                           ips        average  deviation         median         99th %\\nredix_pool                   70.44       14.20 ms    \xb136.07%       13.30 ms       50.60 ms\\nrun_redix_pipeline           30.56       32.73 ms    \xb165.74%       47.26 ms       91.99 ms\\nredix_pool_pipelined         21.55       46.40 ms     \xb13.87%       47.59 ms       48.12 ms\\nredix                        13.84       72.28 ms     \xb19.91%       72.09 ms       80.31 ms\\nfinch_get                     0.55     1814.88 ms     \xb12.44%     1814.88 ms     1846.24 ms\\nfinch_post                    0.54     1859.71 ms     \xb10.70%     1859.71 ms     1868.97 ms\\n```\\n\\n\\nThe results show that running Redis protocol is well over 100x faster than relying on HTTP. By default Phoenix sends extra headers for the content type and other information. In addition there is extra overhead encoding and decoding the values for URL encoding and JSON.\\n\\nOverall using Redis as a Protocol instead of HTTP results in orders of magnitude higher troughput.\\n\\n## Conclusion\\n\\nWe wrote a high-performance server based on the Redis Protocol in around 10 minutes. This server can handle thousands of connections easily and has minimal overhead. One downside is that load balancing becomes more of a challenge when doing multi-node deploys when using a protocol other than HTTP.\\n\\nIf you have a one or thousands of clients that need to communicate with a server in the fastest way possible, consider using Redis as your protocol of choice instead of HTTP."},{"id":"time-for-a-change","metadata":{"permalink":"/blog/time-for-a-change","source":"@site/blog/2021-11-08-time-for-a-change/index.md","title":"Time for a Change - Announcing Statetrace","description":"Data auditing with Statetrace","date":"2021-11-08T00:00:00.000Z","formattedDate":"November 8, 2021","tags":[{"label":"statetrace","permalink":"/blog/tags/statetrace"},{"label":"postgres","permalink":"/blog/tags/postgres"},{"label":"mysql","permalink":"/blog/tags/mysql"},{"label":"auditing","permalink":"/blog/tags/auditing"}],"readingTime":4.095,"truncated":true,"authors":[{"name":"Kyle Hanson","title":"CEO of Statetrace","url":"https://github.com/hansonkd","imageURL":"https://github.com/hansonkd.png","key":"kyle-hanson"}],"prevItem":{"title":"Build an Elixir Redis Server that\'s 100x faster than HTTP","permalink":"/blog/redis-server"}},"content":"The world of application data today is broken. We treat our most valuable asset as a second-class citizen, only keeping the most recent version data available and throwing away critical infomration of how the data got there. It\'s is a hard problem to fix. Statetrace is here to make it easier.\\n\\n\x3c!--truncate--\x3e\\n\\n\x3c!-- ![Docusaurus Plushie](./ipanema.jpg) --\x3e\\n\\n<div style={{\\"background\\": \\"url(/img/ipanema.jpg)\\", \\"backgroundSize\\": \\"150px\\", width: \\"100%\\", height: \\"200px\\", \\"marginTop\\": \\"30px\\", \\"marginBottom\\": \\"30px\\"}}>\\n\\n</div>\\n\\nData auditing is the future of application development. It enables teams to solve tougher problems faster. With Statetrace, teams can develop an auditing solution in hours instead of months and start delivering reliable answers to their customers. Statetrace annotates row level changes from your databases, piping them into webhooks, into data warehouses, or indexing them for fast searches.\\n\\n\\n## Whats wrong today\\n\\nThe world of auditing today has been stuck for decades. There exist [libraries](https://django-simple-history.readthedocs.io/en/latest/) and [tools](https://github.com/etianen/django-reversion) at the application layer to associate changes with who changed them, however these tools are deeply flawed. Because they work at the application layer, they miss things that don\'t go through the application; like migrations or someone connected directly to the DB. More importantly they are strictly framework dependent and do not offer a general solution.\\n\\nCDC pipelines capture the changes accurately but do not associate those changes with application meta information.\\n\\n\\n## How it works\\n\\nStatetrace connects to the [logical replication](https://www.postgresql.org/docs/10/logical-replication.html) of Postgres or the [BinLog](https://dev.mysql.com/doc/internals/en/binary-log-overview.html) of MySQL. By reading events directly from the replication log, Statetrace gets a 100% accurate history of your data. More importantly because it is intefacing with the database instead of the application, Statetrace can work with any framework or language with minimal configuration.\\n\\n\\nThe application annotates transactions by writing to an annotations table in the same transaction that you change other data, associating session and user information with individual row changes.\\n\\n\\n## Solving the \\"Who dunnit?\\"\\n\\nNobody wants to answer the dreaded customer complaint \\"Who changed my data?\\" Even if the customer was the last one to change the data, without a proper auditing solution one might not be able to give a reliable answer. Having uncertainty around the history of data puts a company\'s reputation at risk.\\n\\nStatetrace puts the answers to these questions at your fingertips. With an annotated audit log, each row change is associated with meta-information about who in the application changed the data. Pipe these changes into the destination of your choice for easy searching.\\n\\n\\n\\n## Github for Code. Statetrace for Data.\\n\\n\\nVersion control for code is integral to the development process. Companies spend billions of dollars every year on developer salaries and want to keep that investment of developer output. Data about what the code was and who changed it is so valuable that a multi-billion dollar industry has grown to support those needs. \\n\\nHowever, companies are throwing away money when it comes to their actual bread and butter: the application data. The stream of changes from application data are a gold mine for solving problems and answering questions. But the vast majority of companies today throw away these changes, because they have little value as they don\'t connect the change to who made the change. This is bad, because you don\'t know what type of questions you might want to know in the future and once you throw it away, its gone for ever.\\n\\nStatetrace is solving this problem. Statetrace makes the stream of changes useful by associating the change with who changed it and simplifying piping these changes into other data sources.\\n\\n## Time traveling SQL\\n\\nOnce all changes from a DB are collected, they can be used to recreate transaction-level point-in-time snapshots of your entire database, a particular table, or just a single row. This allows you to easily go back to see what a the result of a query was. It also helps you answer more interesting questions in data analytics as you can compare two points in time in a single query all in your existing data warehouse.\\n\\n\\n## Compliance focused\\n\\nYour data belongs with you. Statetrace is designed to be run on-prem, leaving you in complete control of your data. Whether you are running a HIPAA deployment or need to stay SOC 2 compliant, Statetrace works with your compliance team to succeed.\\n\\n\\n## Statetrace Core\\n\\nUsers can try [Statetrace Core](/docs/intro) today for free. Its a limited edition of statetrace without a UI, but with all of the power. Try it out locally to quickly connect your database and start scanning within minutes.\\n\\n\\n## Statetrace Enterprise\\n\\nOur flagship product is [Statetrace for Enterprise](https://www.statetrace.com). Its the full featured Statetrace experience with a robust UI, enterprise level user permissions, pre-constructed SQL models for time-travel and support from our customer success team.\\n\\n## The future\\n\\nWe are developing the highest quality auditing experience. If what we are doing sounds interesting, reach out at [hello@statetrace.com](mailto:hello@statetrace.com) and we would love to tell you about what we are working on."}]}')}}]);